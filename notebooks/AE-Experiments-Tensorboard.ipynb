{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dcb5e52",
   "metadata": {},
   "source": [
    "# AE-LEGO Training with Tensorboard logging\n",
    "This notebook uses refined loss-function and `tensorboard` logging.\n",
    "\n",
    "* [Dataset](#data)\n",
    "* [Loss setup](#loss)\n",
    "* [Experiment setup](#exp)\n",
    "* [Run](#run):\n",
    "    * [VAE](#vae)\n",
    "    * [DVAE](#dvae)\n",
    "    * [Twin-VAE](#twin)\n",
    "    * [Hydra-VAE](#hvae)\n",
    "    * [Hydra-DVAE](#hdvae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cf6f1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:28:09.920478Z",
     "iopub.status.busy": "2023-11-04T07:28:09.919681Z",
     "iopub.status.idle": "2023-11-04T07:28:11.942210Z",
     "shell.execute_reply": "2023-11-04T07:28:11.941366Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colormaps, ticker\n",
    "from IPython.display import SVG\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import SGD, AdamW\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81322936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:28:11.946251Z",
     "iopub.status.busy": "2023-11-04T07:28:11.945981Z",
     "iopub.status.idle": "2023-11-04T07:28:13.068246Z",
     "shell.execute_reply": "2023-11-04T07:28:13.067461Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scripts.backbone import *\n",
    "from scripts.aelego import *\n",
    "from scripts.experiment import *\n",
    "from scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b58ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:28:13.073533Z",
     "iopub.status.busy": "2023-11-04T07:28:13.072814Z",
     "iopub.status.idle": "2023-11-04T07:28:13.079123Z",
     "shell.execute_reply": "2023-11-04T07:28:13.078205Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print('GPU' if DEVICE == 'cuda' else 'no GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235b099",
   "metadata": {},
   "source": [
    "<a name=\"data\"></a>\n",
    "\n",
    "## Dataset\n",
    "MINST is a good fit for this simple experiment: it is categorical but also continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e64ad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:28:14.323168Z",
     "iopub.status.busy": "2023-11-04T07:28:14.323004Z",
     "iopub.status.idle": "2023-11-04T07:28:14.368352Z",
     "shell.execute_reply": "2023-11-04T07:28:14.367574Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset = MNIST(root='./data', train=True, download=True)\n",
    "testset  = MNIST(root='./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a152a1d",
   "metadata": {},
   "source": [
    "Define semantic channel if any."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06d021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:28:14.379316Z",
     "iopub.status.busy": "2023-11-04T07:28:14.379087Z",
     "iopub.status.idle": "2023-11-04T07:28:14.383905Z",
     "shell.execute_reply": "2023-11-04T07:28:14.382641Z"
    }
   },
   "source": [
    "    # use data labels\n",
    "    SEMANTIC_DIM = 10\n",
    "    SEMANTIC_LABELS = list(range(10))\n",
    "    dataset = AEDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d950509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # make up some labels\n",
    "    class ContextDataset(AEDataset):\n",
    "        def __getitem__(self, idx):\n",
    "            X, Y, C = super().__getitem__(idx)\n",
    "            labels = {1:0, 4:0, 7:0, 0:1, 8:1, 2:2, 3:2, 5:2, 6:3, 9:3}\n",
    "            return X, Y, labels[C]\n",
    "\n",
    "    SEMANTIC_DIM = 4\n",
    "    SEMANTIC_LABELS = ['1,4,7','0,8','2,3,5','6,9']\n",
    "    dataset = ContextDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc481587",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "    SEMANTIC_DIM = 0\n",
    "    SEMANTIC_LABELS = []\n",
    "    dataset = AEDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bef668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:28:14.388069Z",
     "iopub.status.busy": "2023-11-04T07:28:14.387033Z",
     "iopub.status.idle": "2023-11-04T07:28:14.403539Z",
     "shell.execute_reply": "2023-11-04T07:28:14.402830Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make demo-batch\n",
    "for demo_batch in DataLoader(dataset(testset), batch_size=16, shuffle=True):\n",
    "    X, Y, C = demo_batch\n",
    "    break\n",
    "show_inputs(demo_batch)\n",
    "show_targets(demo_batch)\n",
    "X.shape, Y.shape, C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7747be97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T07:21:08.780172Z",
     "iopub.status.busy": "2023-10-30T07:21:08.779836Z",
     "iopub.status.idle": "2023-10-30T07:21:08.783731Z",
     "shell.execute_reply": "2023-10-30T07:21:08.782801Z"
    },
    "scrolled": false
   },
   "source": [
    "<a name=\"loss\"></a>\n",
    "\n",
    "## Loss refined\n",
    "Let's construct our post-R&D loss-function. The actual initialization values will vary depend on R&D outcome for the specific dataset. Here we use that initialization to set trainable weighs for our prospect loss-components.\n",
    "We also use external logger (`tensorboard`) instead of keeping track inside the loss itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e00db4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:28:15.178225Z",
     "iopub.status.busy": "2023-11-04T07:28:15.177787Z",
     "iopub.status.idle": "2023-11-04T07:28:15.195400Z",
     "shell.execute_reply": "2023-11-04T07:28:15.194663Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Trainable mixer with opinionated init and visual evaluation utilities\n",
    "    \"\"\"\n",
    "    # reconstruction keys (static value; required)\n",
    "    REC = ['rec-AE', 'rec-VAE', 'rec-DVAE']\n",
    "    # regularizers keys (could be trainable; optional)\n",
    "    REG = ['KLD-Gauss', 'KLD-Gumbel',\n",
    "           'Contrast-Gauss', 'Contrast-Gumbel',\n",
    "           'Align-Gauss', 'Align-Gumbel']\n",
    "    \n",
    "    KEYS = REC + REG + ['Temperature']\n",
    "    \n",
    "    def __init__(self,\n",
    "                 keys: list,\n",
    "                 init: dict,\n",
    "                 logger: SummaryWriter,\n",
    "                 categorical_dim: int = None,\n",
    "                 trainable: bool = False):\n",
    "        \n",
    "        super().__init__()\n",
    "        # outputs ids\n",
    "        self.keys = keys        \n",
    "        # initialize losses\n",
    "        self.loss = {\n",
    "            'Reconstruction':  ReconstructionLoss(nn.MSELoss(reduction='mean'),\n",
    "                                                  weight=init.get('Reconstruction', 0)),\n",
    "            'KLD-Gauss':       KLDGaussianLoss(reduction='mean',\n",
    "                                               weight=init.get('KLD-Gauss', 0), trainable=True),\n",
    "            'KLD-Gumbel':      KLDGumbelLoss(categorical_dim, reduction='mean',\n",
    "                                             weight=init.get('KLD-Gumbel', 0), trainable=True),\n",
    "            'Contrast-Gauss':  ContrastLoss(weight=init.get('Contrast-Gauss', 0), trainable=True),\n",
    "            'Contrast-Gumbel': ContrastLoss(weight=init.get('Contrast-Gumbel', 0), trainable=True),\n",
    "            'Align-Gauss':     AlignLoss(weight=init.get('Align-Gauss', 0), trainable=True),\n",
    "            'Align-Gumbel':    AlignLoss(weight=init.get('Align-Gumbel', 0), trainable=True),\n",
    "            'Temperature':     TauLoss(weight=init.get('Temperature', 0), trainable=True),\n",
    "        }\n",
    "        # track all components separately\n",
    "        self.logger = logger\n",
    "        self.mode = 'train' if self.training else 'test'\n",
    "        self.timer = { 'train':0, 'test':0 }\n",
    "                \n",
    "    def forward(self, outputs, targets):\n",
    "        loss = {}\n",
    "        # unpack inputs and calculate all losses (even those not in training)\n",
    "        for i, (k, v) in enumerate(zip(self.keys, outputs)):\n",
    "            if k in self.REC:\n",
    "                loss[k] = self.loss['Reconstruction'](v, targets)\n",
    "            elif k == 'mean':\n",
    "                loss['KLD-Gauss'] = self.loss['KLD-Gauss'](v, outputs[i + 1])\n",
    "                loss['Contrast-Gauss'] = self.loss['Contrast-Gauss'](v)\n",
    "            elif k == 'z': ### do mean instead of z for more stable training\n",
    "                z = v\n",
    "            elif k == 'log-variance':\n",
    "                assert 'KLD-Gauss' in loss\n",
    "            elif k == 'q':\n",
    "                loss['KLD-Gumbel'] = self.loss['KLD-Gumbel'](v)\n",
    "                loss['Contrast-Gumbel'] = self.loss['Contrast-Gumbel'](v)\n",
    "            elif k == 'p': ### do q instead of p for more stable training\n",
    "                p = v\n",
    "            elif k == 'z-context':\n",
    "                loss['Align-Gauss'] = self.loss['Align-Gauss'](z, v)\n",
    "            elif k == 'p-context':\n",
    "                loss['Align-Gumbel'] = self.loss['Align-Gumbel'](p, v)\n",
    "            elif k == 'tau':\n",
    "                tau = v.squeeze()\n",
    "                loss['Temperature'] = self.loss['Temperature'](tau)\n",
    "                \n",
    "        # track all variables in their original scale for visual evaluation\n",
    "        mode = 'train' if self.training else 'test'\n",
    "        vals = [loss[x].item() for x in self.KEYS if x in loss]\n",
    "        self.track = [k for k in self.KEYS if k in loss]\n",
    "        for k,v in zip(self.track, vals):\n",
    "            self.logger.add_scalar(f'Loss:{k}/{mode}', v, self.timer[mode])\n",
    "        mixer_loss = 0\n",
    "        for k in self.REG:\n",
    "            if k in self.track:\n",
    "                self.logger.add_scalar(f'Mixer:{k}/{mode}', self.loss[k].weight.item(), self.timer[mode])\n",
    "                mixer_loss += (self.loss[k].weight ** 4).squeeze()\n",
    "        self.logger.add_scalar(f'Temperature/{mode}', tau, self.timer[mode])\n",
    "        \n",
    "        rec = [loss[k] for k in self.REC if k in loss]\n",
    "        # use only those included in config\n",
    "        reg = [loss[k] for k in self.REG if k in loss]\n",
    "        loss = torch.sum(torch.stack(rec + reg))\n",
    "        # add mixer regularization\n",
    "        loss += mixer_loss\n",
    "        self.logger.add_scalar(f'Loss:Mixer/{mode}', mixer_loss, self.timer[mode])\n",
    "        # this usually done by trainer otherwise we do it here\n",
    "        self.logger.add_scalar(f'Loss:Total/{mode}', loss, self.timer[mode])\n",
    "        self.timer[mode] += 1\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a39b38",
   "metadata": {},
   "source": [
    "<a name=\"exp\"></a>\n",
    "\n",
    "## Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13e0cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def experiment(model: nn.Module,\n",
    "               tag: str,\n",
    "               init: dict,\n",
    "               latent_dim: int,\n",
    "               categorical_dim: int = None,\n",
    "               encoder_semantic_dim: int = SEMANTIC_DIM,\n",
    "               decoder_semantic_dim: int = SEMANTIC_DIM,\n",
    "               trainable: bool = False,\n",
    "               tau: float = 0.1,\n",
    "               dataset: Dataset = dataset,\n",
    "               batch_size: int = 16,\n",
    "               learning_rate: float = 1e-5,\n",
    "               epochs: int = 5):\n",
    "    \"\"\"\n",
    "    build configuration and run training\n",
    "    \"\"\"\n",
    "    encoder = get_encoder()\n",
    "    decoder = get_decoder()\n",
    "    \n",
    "    context = decoder_semantic_dim > 0 or encoder_semantic_dim > 0\n",
    "    \n",
    "    if model == TwinVAE:\n",
    "        #assert categorical\n",
    "        model = TwinVAE(encoder, decoder, latent_dim, categorical_dim,\n",
    "                        encoder_semantic_dim, decoder_semantic_dim, tau).to(DEVICE)\n",
    "        print('Model: TwinVAE')\n",
    "    elif model == HydraVAE:\n",
    "        #dim = CATEGORICAL_DIM if categorical else None\n",
    "        model = HydraVAE(encoder, decoder, latent_dim, categorical_dim,\n",
    "                         encoder_semantic_dim, decoder_semantic_dim, tau).to(DEVICE)\n",
    "        print(f'Model: {\"Categorical \" if categorical_dim else \"\"}HydraVAE')\n",
    "    elif model == DVAE:\n",
    "        #assert categorical\n",
    "        model = DVAE(encoder, decoder, latent_dim, categorical_dim,\n",
    "                     encoder_semantic_dim, decoder_semantic_dim, tau).to(DEVICE)\n",
    "        print('Model: DVAE')\n",
    "    else:\n",
    "        model = VAE(encoder, decoder, latent_dim, \n",
    "                    encoder_semantic_dim, decoder_semantic_dim, tau).to(DEVICE)\n",
    "        print('Model: VAE')\n",
    "\n",
    "    init['Temperature'] = tau\n",
    "    \n",
    "    logger = SummaryWriter(f'./runs/mnist-{tag}/')\n",
    "    criterion = AELoss(model.keys, init, logger, categorical_dim, trainable=trainable).to(DEVICE)\n",
    "    params = [p for p in model.parameters()] + [p for p in criterion.parameters()]\n",
    "    optimizer = SGD(params, lr=learning_rate, momentum=0.8)\n",
    "\n",
    "    history, results = [],[]\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        \n",
    "        train_history = train_epoch(model, dataset(trainset), context,\n",
    "                                    criterion, optimizer, epoch, batch_size=batch_size)\n",
    "        \n",
    "        test_history = validate(model, dataset(testset), context,\n",
    "                                criterion, epoch, batch_size=batch_size)\n",
    "        \n",
    "        history.append((np.mean(train_history), np.mean(test_history)))\n",
    "    logger.flush()\n",
    "    logger.close()\n",
    "    show_targets(demo_batch)\n",
    "    for key in criterion.REC:\n",
    "        if key in criterion.track:\n",
    "            show_model_output(model, demo_batch, criterion.keys.index(key), key[4:])\n",
    "    return model, criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b085b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:28:15.199044Z",
     "iopub.status.busy": "2023-11-04T07:28:15.198739Z",
     "iopub.status.idle": "2023-11-04T07:28:15.202819Z",
     "shell.execute_reply": "2023-11-04T07:28:15.201803Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LATENT_DIM = 3\n",
    "CATEGORICAL_DIM = 10\n",
    "\n",
    "suffix = f'{LATENT_DIM}-{CATEGORICAL_DIM}-{SEMANTIC_DIM}' # for image-save path\n",
    "\n",
    "kwargs = { # shared arguments\n",
    "    'encoder_semantic_dim': 0,\n",
    "    'decoder_semantic_dim': SEMANTIC_DIM,\n",
    "    'tau': 0.1,\n",
    "    'dataset': dataset,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-5,\n",
    "    'trainable': True,\n",
    "    'epochs': 3,\n",
    "}\n",
    "\n",
    "index, results = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9deac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!rm -rf runs/mnist*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac98bcd",
   "metadata": {},
   "source": [
    "<a name=\"run\"></a>\n",
    "\n",
    "## Run\n",
    "In this section we use trainable loss components and log to `tensorboard`.\n",
    "Depend on where `tensorboard` is running:\n",
    " \n",
    "     $ tensorboard --logdir={LOGDIR} --bind_all\n",
    "\n",
    "\n",
    "<a name=\"vae\"></a>\n",
    "\n",
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93aead9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T07:28:15.222006Z",
     "iopub.status.busy": "2023-11-04T07:28:15.221412Z",
     "iopub.status.idle": "2023-11-04T07:48:47.512612Z",
     "shell.execute_reply": "2023-11-04T07:48:47.511620Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tag = 'vae-trained'\n",
    "init = {'Reconstruction': -2.}\n",
    "model, criterion = experiment(VAE, tag, init, LATENT_DIM, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f30aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visual evaluation\n",
    "vectors, labels = get_embeddings(model.encoder, dataset(trainset), f'{tag}-{suffix}')\n",
    "show_latent_space(vectors, labels, f'{tag}-{suffix}')\n",
    "show_reconstruction_map(model.decoder, f'{tag}-{suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32300909",
   "metadata": {},
   "source": [
    "<a name=\"dvae\"></a>\n",
    "\n",
    "### Discrete/Categorical VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede587b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tag = 'dvae-trained'\n",
    "init = {'Reconstruction': -2.}\n",
    "model, criterion = experiment(DVAE, tag, init, LATENT_DIM, CATEGORICAL_DIM, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f3886",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_categoric_reconstruction_map(model.decoder, LATENT_DIM, CATEGORICAL_DIM, f'{tag}-{suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f80a5",
   "metadata": {},
   "source": [
    "<a name=\"twin\"></a>\n",
    "\n",
    "### Twin-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0289b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tag = 'twin-trained'\n",
    "init = {'Reconstruction': -2.}\n",
    "model, criterion = experiment(TwinVAE, tag, init, LATENT_DIM, CATEGORICAL_DIM, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954d638",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vectors, labels = get_embeddings(model.vae.encoder, dataset(trainset), f'{tag}-{suffix}')\n",
    "show_latent_space(vectors, labels, f'{tag}-{suffix}')\n",
    "show_reconstruction_map(model.vae.decoder, f'{tag}-{suffix}')\n",
    "show_categoric_reconstruction_map(model.dvae.decoder, LATENT_DIM, CATEGORICAL_DIM, f'{tag}-{suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebcebb2",
   "metadata": {},
   "source": [
    "<a name=\"hvae\"></a>\n",
    "\n",
    "### Hydra-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44ad9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tag = 'hvae-trained'\n",
    "config = {'Reconstruction': -2.}\n",
    "model, criterion = experiment(HydraVAE, tag, init, LATENT_DIM, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0ede6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vectors, labels = get_embeddings(model.vae.encoder, dataset(trainset), f'{tag}-{suffix}')\n",
    "show_latent_space(vectors, labels, f'{tag}-{suffix}')\n",
    "show_reconstruction_map(model.vae.decoder, f'{tag}-{suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015bfa0",
   "metadata": {},
   "source": [
    "<a name=\"hdvae\"></a>\n",
    "\n",
    "### Hydra-DVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34b006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tag = 'hdvae-trained'\n",
    "config = {'Reconstruction': -2.}\n",
    "model, criterion = experiment(HydraVAE, tag, init, LATENT_DIM, CATEGORICAL_DIM, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc5f1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_categoric_reconstruction_map(model.dvae.decoder, LATENT_DIM, CATEGORICAL_DIM, f'{tag}-{suffix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a3e50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
